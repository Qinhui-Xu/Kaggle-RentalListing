# paths is not strongly associated with with closeness from
# outbound paths.
#
# In- and out-degree are highly correlated with eigenvector
# centrality, indicating that the students that talk the most to
# others (or, relatedly, are talked to the most by others) are
# also the ones that are connected to other highly connected
# students -- possibly indicating high density cliques around
# these individuals.
#
# Betweennes shows the highest corelation with outdegree, follwed
# by indegree. In the case of this particular network, it seems
# that the individuals that talk to the most others are the
# likeliest to serve as bridges between the particular cliques
# (see, e.g., 22 in the plot).
data(studentnets.S641, package = "NetData")
# Reduce to non-zero edges and build a graph object
s641_full_nonzero_edges <- subset(s641_full_data_frame, (social_tie > 0 | task_tie > 0))
head(s641_full_nonzero_edges)
s641_full <- graph.data.frame(s641_full_nonzero_edges)
summary(s641_full)
s641_full_nonzero_edges <- subset(s641_full_data_frame, (social_tie > 0 | task_tie > 0))
head(s641_full_nonzero_edges)
s641_full <- graph.data.frame(s641_full_nonzero_edges)
summary(s641_full)
s641_social <- delete.edges(s641_full, E(s641_full)[get.edge.attribute(s641_full,name = "social_tie")==0])
s641_social <- delete.vertices(s641_social, V(s641_social)[degree(s641_social)==0])
summary(s641_social)
s641_task <- delete.edges(s641_full, E(s641_full)[get.edge.attribute(s641_full,name = "task_tie")==0])
s641_task <- delete.vertices(s641_task, V(s641_task)[degree(s641_task)==0])
summary(s641_task)
head(s641_full_nonzero_edges)
task_layout <- layout.fruchterman.reingold(s641_task)
plot(s641_task, layout=task_layout, edge.arrow.size=.5)
social_layout <- layout.fruchterman.reingold(s641_social)
plot(s641_social, layout=social_layout, edge.arrow.size=.5)
task_layout <- layout.fruchterman.reingold(s641_task)
plot(s641_task, layout=task_layout, edge.arrow.size=.5)
social_layout <- layout.fruchterman.reingold(s641_social)
plot(s641_social, layout=social_layout, edge.arrow.size=.5)
install.packages("ggdendro")
install.packages("sna")
library(sna)
data(florentine)
library(network)
data(florentine)
library(igraph)
data(florentine)
install.packages("Padgett")
data(flo)
library(igraph)
#--------------------------------------------------
library(sna)
data(flo)
flobusiness # first relation
flomarriage # second relation
flomatrix <- as.matrix(flobusiness)
g <- graph.adjacency(flomatrix,
mode="undirected",
weighted =NULL)
plot(g)
install.o
library(igraph)
#--------------------------------------------------
library(sna)
library(statnet)
data(florentine)
flobusiness # first relation
flomarriage # second relation
flomatrix <- as.matrix(flobusiness)
g <- graph.adjacency(flomatrix,
mode="undirected",
weighted =NULL)
plot(g)
library(igraph)
#--------------------------------------------------
library(sna)
library(statnet)
data(florentine)
flobusiness # first relation
flomarriage # second relation
flomatrix <- as.matrix(flobusiness)
g <- graph.adjacency(flomatrix,
mode="undirected",
weighted =NULL)
plot(g)
#----------
install.packages("statnet")
library(igraph)
#--------------------------------------------------
library(sna)
library(statnet)
data(florentine)
flobusiness # first relation
flomarriage # second relation
flomatrix <- as.matrix(flobusiness)
g <- graph.adjacency(flomatrix,
mode="undirected",
weighted =NULL)
plot(g)
flomatrix <- as.matrix(flomarriage)
g <- graph.adjacency(flomatrix,
mode="undirected",
weighted =NULL)
plot(g)
library(igraph)
#--------------------------------------------------
library(sna)
library(statnet)
data(florentine)
flobusiness # first relation
flomarriage # second relation
flomatrix <- as.matrix(flobusiness)
#flomatrix <- as.matrix(flomarriage)
g <- graph.adjacency(flomatrix,
mode="undirected",
weighted =NULL)
plot(g)
#--------------------------------------------------
set.seed(1122)
eb <- edge.betweenness.community(g)
plot (eb,g)
set.seed(1122)
ev <- leading.eigenvector.community(g)
plot (ev,g)
set.seed(1122)
fg <- fastgreedy.community(g)
plot (fg,g)
set.seed(1122)
wt <- walktrap.community(g)
plot (wt,g)
233.51758+ 4.59744+0.58355213
233.51758+ 4.59744+0.58355*213
105.40249-33.36158
105.40249-33.36158+1.25348*7
105.40249-33.36158+1.25348*162
-33.36158-22.62693
#=============================================================#
#                                                             #
#  Basics of Exponential Random Graph Models in R             #
#  (Adapted from Statnet.org papers)                          #
#  COMM 645 - Communication Networks                          #
#  Katya Ognyanova, 10/10/2012                                #
#                                                             #
#=============================================================#
# This lab will use the R packages ergm & sna:
install.packages("ergm")
install.packages("sna")
library(ergm)
library(sna)
# ERGM on a symmetric network: the Florentine families
#=============================================================#
# As is traditional in ergm tutorials, we'll use the Padgett florentine marriage & business ties
# dataset included with the ergm package:
data(florentine)
# The data contains two network objects - one with marital and another one
# with business relationships between Florentine families.
flobusiness; flomarriage;
# Exponential random graph models - what terms can we use in a model?
help('ergm-terms')
# Let's estimate a simple  model which only examines density (edge term)
# The format of the ergm command is ergm(YourNetwork ~ Signature1 + Signature2 + ...)
# where YourNetwork can be a matrix or a network object.
flo.mar.1 <- ergm(flomarriage ~ edges)
flo.mar.1
summary(flo.mar.1)
# We get a negative edge parameter since the network is rather sparse.
# The edge parameter here is the log of the edge odds, i.e. log(#dyads-w-edge/#dyads-no-edge)
# The network has 20 ties of 120 possible ties. Let's calculate the log odds ourselves:
# [ remember that an event with probability p has odds of p/(1-p) and log odds of log(p/(1-p)) ]
log(20/(120-20)) # We get -1.609, the same as the edge parameter in the erg model.
# The corresponding probability is .167:
exp(-1.609)/(1+exp(-1.609)) # you can also get that using inv.logit() from package "boot"
# Next we look at a fancier model that includes triangles in addition to edges:
flo.mar.2 <- ergm(flomarriage ~ edges + triangles, seed=1)
flo.mar.2
summary(flo.mar.2)
# The triangle coefficient is not significant - so this is not a signature
# driving the network formation. What do the coefficients tell us?
# Conditional log-odds of a tie between two actors here =
# = -1.675*(change in the number of ties) + 0.158 * (change in the number of triangles)
# = -1.675*1 + 0.158*(change in the number of triangles)
#
# if the tie will not add any triangles to the network, its log-odds = -1.675.
# if it will add one triangle to the network, its log-odds = -1.675 + 0.158 = -1.517
# if it will add two triangles to the network, its log-odds = -1.675 + 0.158*2 = -1.359
# The corresponding probabilities are 0.158, 0.180, and 0.204.
#
# (note: we're using a stochastic algorithm - so you will get slightly different estimates
# if you rerun the model. Here we use seed=1 to make sure we'll get the same results every time)
# There are a large number of other structural signatures you could add paramteters for.
# For instance 2-stars: kstar(2), 3-stars: kstar(3) isolates: isolates, etc.
# Let's run a model checking whether edges in the Florentine business network are predicted by
# edges in the marriage network. To do that, we can use an edge covariate parameter edgecov()
# As in: ergm(MyNetwork ~ Signature1 + Signature2 + ... + edgecov(AnotherNetwork))
flo.mar.3 <- ergm(flobusiness ~ edges + edgecov(flomarriage))
flo.mar.3
summary(flo.mar.3)
# We can also use node attributes in an erg model.
# For the Florentine families, we have an attribute called "wealth" in the network object.
w.vec <- flomarriage %v% 'wealth'  # Store the node wealth in a numeric vector.
w.vec
gplot(flomarriage, vertex.cex=w.vec/20)	# plot the network with vertex size proportional to wealth
# Let's test whether the edge probabilities are a function of wealth:
# Are wealthy families more likely to form ties?
flo.mar.4 <- ergm(flomarriage ~ edges + nodecov("wealth"))
flo.mar.4
summary(flo.mar.4)
# Yes, there is a significant positive main effect for wealth:
# - The p-value for the wealth parameter makes it significant at the .05 level.
# - It's positive, which means we see more of that configuratoin than we'd expect by chance.
# ERGM on a directed network: Sampson Monastery
#=============================================================#
# ERG model of a directed network - the liking relations between monks
# in Sampson's dataset.
data(samplk)
samplk1; samplk2; samplk3
plot(samplk3)
# Is there a statistically significant tendency for ties to be reciprocated?
samp.mod.1 <- ergm(samplk3 ~ edges + mutual)
summary(samp.mod.1)
# Conditional log-odds of two actors forming a tie =
# = -2.15 * change in the number of ties + 2.3 * change in number of mutual dyads
# If adding the tie will not make a dyad reciprocal, its log-odds = -2.15
# if it will add a mutual dyad to the network, its log-odds = -2.15 + 2.3 = 0.15
# ERGM with node attributes: Faux Mesa High
#=============================================================#
# Faux mesa high is simulated data representing a high-school friendship network.
# Attributes for each node (student) include gender, race, and grade.
data(faux.mesa.high)
fmh.net <- faux.mesa.high
plot(fmh.net)
fmh.net
# Taking a look at gender
plot(fmh.net, vertex.col='Sex')
# Taking a look at the grade of the students
plot(fmh.net, vertex.col='Grade')
# Taking a look at the race of the students
plot(fmh.net, vertex.col='Race')
# A simple model that includes just the edge (density) parameter:
fmh.mod.1 <- ergm(fmh.net ~ edges)
summary(fmh.mod.1)
# NODEMATCH
# Are nodes with the same attribute levels more likely to be connected?
# Do high-school students tend to have friends of the same grade?
fmh.mod.2 <- ergm(fmh.net ~ edges + nodematch("Grade"))
summary(fmh.mod.2)
# We can add an attribute diff=T to nodematch to get a separate parameter for
# each level of the categorical variable.
# Here, a separate parameter for each grade:
fmh.mod.3 <- ergm(fmh.net ~ edges + nodematch("Grade", diff=T))
summary(fmh.mod.3)
# How about gender and race?
fmh.mod.4 <- ergm(fmh.net ~ edges + nodematch("Grade") + nodematch("Race") + nodematch("Sex"))
summary(fmh.mod.4)
# NODEMIX
# Nodemix will add a parameter for each combination of levels for the categorical variable.
# Let's look at the parameters for edges between students from different race groups:
fmh.mod.5 <- ergm(fmh.net ~ edges + nodemix("Race"))
summary(fmh.mod.5)
table(fmh.net %v% "Race")  			# Check out race frequencies
mixingmatrix(fmh.net, "Race")   # Check out # of links between/within groups
# Note that we got -Inf parameters in the model for configurations
# that don't exist in the observed network at all.
# NODEFACTOR
# Main effect of a categorical attribute.
# Are some types of nodes more likely to form ties than others?
# For example, are boys forming friendship ties more actively than girls?
fmh.mod.6 <- ergm(fmh.net ~ edges + nodematch("Grade", diff = T) + nodefactor("Sex"))
summary(fmh.mod.6)
# Negative parameter for males means females are more actively forming friendships.
# NODECOV
# Main effect of a continuous attribute (we'll treat grade as continuous here).
# Are nodes with high levels on a continuous attribute more likely to form ties?
# Let's check if students with higher values on attribute "Grade" tend to form more friendships.
fmh.mod.7 <- ergm(fmh.net ~ edges + nodecov("Grade") + nodematch("Sex"))
summary(fmh.mod.7)
# Note that this is the parameter version for undirected networks.
# For directed networks, we have nodeicov (for incoming links)
# and nodeocov (for outgoing links).
# Similarly nodefactor has directev versions nodeifactor & nodeofactor.
# ABSDIFF
# For continuous attributes: are people more likely to be connected to others
# who have similar values on an attribute? Absdiff = abs(ValueNode1-ValueNode2)
# Here, are students more likely to have friends close to their own grade?
# (that is, links i->j are more likely for smaller values of abs(grade of i - grade of j))
fmh.mod.8 <- ergm(fmh.net ~ edges + absdiff("Grade") + nodematch("Sex"))
summary(fmh.mod.8)
# Simulating networks based on a model
#=============================================================#
# After we have estimated model coefficients, we can draw graphs from
# the probability distribution defined by those parameter values.
# If our model was good, the graphs we draw from this distribution
# should be similar to our observed data.
# Simulate 15 networks based on the fmh.mod.6 model:
fmh.mod.8.sim <- simulate(fmh.mod.8, nsim=15)
summary(fmh.mod.8.sim)
# All the simulated network are stored in the returned object:
class(fmh.mod.8.sim)
# We can access any of them and take a look at it:
fmh.mod.8.sim[[1]]
# Goodnes of Fit and MCMC diagnostics
#=============================================================#
# After estimating parameters for your mode, you want to know how well
# it fits the observed data.
# Let's check the goodness of fit for one of our initial models of the Padgett network.
# Check how well the degree distribution of the networs generated from our model
# match the degree distribution of the observed network:
summary(flo.mar.4) # Take a look at the model
flo.mar.4.gof <- gof(flo.mar.4 ~ degree) # goodness of fit for degree distribution
# If this was a directed network, we could check gof for in- or out-degree instead
# using gof(flo.mar.4 ~ idegree) or gof(flo.mar.4 ~ odegree)
flo.mar.4.gof # Take a look at the observed & simulated values
plot(flo.mar.4.gof) # plot the observed & simulated values
# The resutls contain 1 row for each possible node degree (e.g. row 0 - number of isolates,
# row 1 - number of nodes with only 1 link, row 2 - # of nodes with 2 links, etc.)
# The first column contains the counts from the observed network, the other give staticstics
# from the simulated networks.
# The fit is not bad - observed values are within the confidence interval (see the plot).
# P values are high (the observed & simulated values do not differ significantly).
# This is one of those rare cases where a high p value is a good thing :)
# We can check the goodness of fit with regard to other network statistics.
# For instance geodesic distance.
# Compare our network with 20 simulated networks based on the flo.mar.4 model:
flo.mar.4.gof2 <- gof(flo.mar.4 ~ distance, nsim=20) # gof based on 20 simulated nets
summary(flo.mar.4.gof2)
plot(flo.mar.4.gof2)
# Here each row in the summary is the number of geodesics with a particular length.
# For instance, we have 20 node pairs in the observed network with shortest paths of 1
# (those correspond to the 20 edges in our observed network).
# Model diagnostics (for MCMC)
# Information about the model that can help diagnose problems.
# Note we can't get (and don't need) these diagnostics for flo.mar.4 since
# it was not estimated using MCMC. This is because it was simple enough
# (i.e. a dyadic independence model) that we did not need MCMC estimation.
mcmc.diagnostics(flo.mar.2)
# It's easier to go through the charts if we save in a PDF file:
pdf("flo_mar_model2.pdf")
mcmc.diagnostics(flo.mar.2)
dev.off()
# We can examine the diagnostics to see whether our model looks ok,
# check for model degeneracy, see if MCMC sample size and burn-in are large enough, etc.
# Read more about interpreting model diagnostics in Section 5 of this document:
# http://statnet.csde.washington.edu/trac/raw-attachment/wiki/Resources/ERGMtutorial.pdf
#=============================================================#
flo.mar.2 <- ergm(flomarriage ~ edges + triangles, seed=1)
flo.mar.2
summary(flo.mar.2)
exp(1.356)
exp(30.1)
0.445-(48/54*0.146+6/54*0.918)
48/54*0.146
48/54
0.445-(0.146*48/54+0.918*6/54)
shiny::runApp('Desktop/FootballProject/Shiny/Shiny2')
runApp('Desktop/FootballProject/Shiny/Shiny2')
getwd()
install.packages("cowplot")
install.packages("gridExtra")
(0.503-(-0.620)^2)/(1-(-0.620)^2)
(1-0.503)*-0.602
0.299194*0.620+0.503
0.299194*0.520
0.299194*0.520+0.503*0.690
30.70255*(1+0.299194-0.503)
tanh(3)
tanh(1+18+30+44)+tanh(6+54+70+88)
1+1.5+1.5+1+1.5+2
8.5/6
17/12
1
1+2+1+1.5+1.5+1.5
9/4
#library(rhdf5)
#library(rhdf5)
library(h2o)
#library(data.table)
h2o.init(nthreads = -1, max_mem_size="6g")
#suppressMessages(library(dplyr))
data <- h2o.importFile("/Users/apple1/Desktop/kaggle/train.csv")
library(h2o)
h2o.init(nthreads = -1, max_mem_size="6g")
train = read.csv("/Users/apple1/Desktop/kaggle/RentalListing/train.csv")
train <- as.h2o(train, destination_frame = "train.hex")
varnames <- setdiff(colnames(train), "interest_level")
#ratios add up to less than 1?
#how to parse data using R in h2o?
split = h2o.splitFrame(train, ratios = c(0.7, 0.29))
traindata <- split[[1]]
validationdata <- split[[2]]
gbm1 <- h2o.gbm(x = varnames
,y = "interest_level"
,training_frame = traindata
,validation_frame = validationdata
,distribution = "multinomial"
,model_id = "gbm1"
#,nfolds = 5
,ntrees = 200
,learn_rate = 0.01
,max_depth = 7
,min_rows = 20
,sample_rate = 0.8
,col_sample_rate = 0.7
,stopping_rounds = 5
,stopping_metric = "logloss"
,stopping_tolerance = 0
,seed=321
)
packages <- c("jsonlite", "dplyr", "purrr")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
df_train <- read.csv(file="/User/apple1/desktop/kaggle/RentalListing/Kaggle-RentalListing/df_train.csv")
setwd("~/Desktop/kaggle/RentalListing/Kaggle-RentalListing")
df_train <- read.csv(file="~/Desktop/kaggle/RentalListing/Kaggle-RentalListing/df_train.csv")
data.table(head(df_train))
library(data.table)
data.table(head(df_train))
names(df_train)
library(syuzhet)
library(DT)
sentiment <- get_nrc_sentiment(df_train$description)
train_df$id<-seq(1:length(train_df$building_id))
df_train$id<-seq(1:length(df_train$building_id))
sentiment <- get_nrc_sentiment(df_train$description)
class(df_train$description)
as.character(df_train$description)
df_train$description <- as.character(df_train$description)
sentiment <- get_nrc_sentiment(df_train$description)
df_train_sent<-merge(df_train,sentiment, by.x="id", by.y="id", all.x=T, all.y=T)
sentiment$id<-seq(1:nrow(sentiment))
df_train_sent<-merge(df_train,sentiment, by.x="id", by.y="id", all.x=T, all.y=T)
df_train_sent
data.table(head(df_train_sent))
write.csv(df_train_sent, file = "train_sent.csv",row.names=FALSE)
#library(lubridate)
library(dplyr)
library(jsonlite)
library(caret)
library(purrr)
library(xgboost)
library(MLmetrics)
library(tidytext)
library(reshape2)
library(data.table)
seed = 1985
set.seed(seed)
train <- fromJSON("/Users/apple1/desktop/kaggle/RentalListing/train.json")
test <- fromJSON("/Users/apple1/desktop/kaggle/RentalListing/test.json")
t1 <- train
t2 <- data.table(bathrooms=unlist(t1$bathrooms)
,bedrooms=unlist(t1$bedrooms)
,building_id=as.factor(unlist(t1$building_id))
,created=as.POSIXct(unlist(t1$created))
,n_photos = as.numeric(sapply(t1$photos, length))
,n_description = as.numeric(sapply(t1$description, nchar))
,n_features = as.numeric(sapply(t1$features, length))
#,description=unlist(t1$description) # parse errors
# ,display_address=unlist(t1$display_address) # parse errors
,latitude=unlist(t1$latitude)
,longitude=unlist(t1$longitude)
,listing_id=unlist(t1$listing_id)
,manager_id=as.factor(unlist(t1$manager_id))
,price=unlist(t1$price)
,interest_level=as.factor(unlist(t1$interest_level))
#,street_adress=unlist(t1$street_address) # parse errors
)
t2[,":="(yday=yday(created)
,month=month(created)
,mday=mday(created)
,wday=wday(created)
,hour=hour(created))]
# expand features
frq_features = table(unlist(t1$features))
top_features = names(frq_features[frq_features>1000])  ## can't set too small due to the limit of run time
t2_exp_feat = t(sapply(t1$features,
function(x) {
as.numeric(top_features %in% x)
}))
t2 = cbind(t2, t2_exp_feat)
write.csv(t2, file = "train_datahandle.csv",row.names=FALSE, na="")
df_train["features"]
t2_exp_feat = t(sapply(df_train_sent$features,
function(x) {
as.numeric(top_features %in% x)
}))
t2_exp_feat
t2_exp_feat = t(sapply(df_train_sent$features,as.numeric))
t2_exp_feat
t2_exp_feat = t(sapply(df_train_sent$features,as.numeric))
head(t2_exp_feat)
1:10 %in% c(1,3,5,9)
as.numeric(1:10 %in% c(1,3,5,9))
sapply(1:5,function(x) matrix(x,2,2), simplify = "array")
top_features
top_description
library(data.table)
df_train <- read.csv(file="~/Desktop/kaggle/RentalListing/Kaggle-RentalListing/df_train.csv")
data.table(head(df_train))
names(df_train)
####### Sentiment Analysis based on description
library(syuzhet)
library(DT)
df_train$id<-seq(1:length(df_train$building_id))
df_train$description <- as.character(df_train$description)
sentiment <- get_nrc_sentiment(df_train$description)
sentiment$id<-seq(1:nrow(sentiment))
df_train_sent<-merge(df_train,sentiment, by.x="id", by.y="id", all.x=T, all.y=T)
data.table(head(df_train_sent))
write.csv(df_train_sent, file = "train_sent.csv",row.names=FALSE)
top_features
top_features
top_features
class(top_features)
